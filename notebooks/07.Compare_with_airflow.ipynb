{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": [
    "# Compare with airflow\n",
    "\n",
    "## 1. Implementation of the core concept of workflow automation\n",
    "\n",
    "| Component\t                 | Description\t                                                         | Prefect Analogy                                                                     | Airflow Analogy                                                            |\n",
    "|----------------------------|----------------------------------------------------------------------|-------------------------------------------------------------------------------------|----------------------------------------------------------------------------|\n",
    "| Task                       | \tThe smallest executable unit (a function, script, or command).\t     | @task decorator                                                                     | PythonOperator, BashOperator, or any Airflow operator.                     |\n",
    "| Flow / DAG                 | \tA directed acyclic graph defining task order and dependencies.      | \t@flow decorator                                                                    | DAG object — defines Directed Acyclic Graph structure.                     |\n",
    "| Task Dependency Management | Defines order and relationships between tasks (upstream/downstream). | Python call order (task_a() → task_b()). Prefect infers dependencies automatically. | Explicitly defined using >> or << operators (task_a >> task_b).            |\n",
    "| Scheduler                  | \tDecides when to run flows (e.g., hourly, daily, triggered).         | \tPrefect deployments & schedules                                                    | Airflow Scheduler with schedule_interval (cron, timedelta, etc.).          |\n",
    "| Executor / Worker          | \tRuns tasks on compute resources (local, Docker, cluster).           | \tPrefect worker(pulls jobs from a Work Pool and executes flows.)                    | Executor — runs tasks via Celery, LocalExecutor, or KubernetesExecutor.    |\n",
    "| State Manager              | \tTracks running, success, retry, fail, cancel states.\t               | Prefect Orion state engine                                                          | askInstance and DagRun states (success, failed, up_for_retry, etc.).       |\n",
    "| Observer / Logger          | \tRecords logs, metrics, and events for debugging.\t                   | Prefect UI & logging                                                                | Airflow Web UI (http://localhost:8080) — DAG-based view.                   |\n",
    "| Configuration Store        | \tHolds environment variables, credentials, or secrets.\t              | Prefect Blocks                                                                      | Connections / Variables in Airflow (stored in metadata DB or environment). |\n",
    "| API / Backend              | \tCentral coordination hub for flows and tasks.\t                      | Prefect API Server                                                                  | Airflow Webserver + Scheduler + Metadata DB (tightly coupled).             |\n",
    "\n"
   ],
   "id": "1556027150bf5dda"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The below figure shows a general comparison between airflow and prefect\n",
    "\n",
    "\n",
    "| Dimension\t            | Prefect\t                                                     | Airflow                                                       |\n",
    "|-----------------------|--------------------------------------------------------------|---------------------------------------------------------------|\n",
    "| Programming model\t    | Python-first flows & tasks (imperative)\t                     | Python like DAGs declarative language                         |\n",
    "| Scheduling\t           | Built-in scheduler; Cloud orchestration optional             | \tMature scheduler, many executors                             |\n",
    "| Dynamic DAGs          | \tStrong support (task mapping, dynamic flows)\t               | Supported but can be complex/anti-patterns                    |\n",
    "| Observability\t        | Rich runtime UI, task metadata, modern UX\t                   | Mature UI, extensive plugins and community tooling            |\n",
    "| Failure handling      | \tBuilt-in task retries, state handlers, idempotency patterns | \tRetries + sensors; more manual wiring for complex behaviors  |\n",
    "| Deployment\t           | Lightweight agents, containers; good Cloud story\t            | Multiple executors (Celery, Kubernetes, Local), heavier infra |\n",
    "| Extensibility\t        | Python SDK, integrations growing                             | \tVery large ecosystem of operators/hooks                      |\n",
    "| Community & maturity\t | Rapidly growing\t                                             | Very large, battle-tested for years                           |\n",
    "| Use cases\t            | Dynamic pipelines, Python-native teams, hybrid cloud         | \tLarge enterprises, complex scheduling needs                  |"
   ],
   "id": "f219a8cd20e802be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1d4fcbfbbcc27cd4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "The below code shows an `DAG` definition in airflow\n",
    "\n",
    "\n",
    "```python\n",
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to run\n",
    "def run_task(task_name:str):\n",
    "    print(f\"Running task {task_name} in airflow worker\")\n",
    "\n",
    "# DAG definition\n",
    "with DAG(\n",
    "    dag_id=\"generate_simply_table\",\n",
    "    start_date=datetime(2025, 9, 3),\n",
    "    schedule_interval=None,  # Manual trigger\n",
    "    catchup=False,\n",
    "    tags=[\"test\"],\n",
    ") as dag:\n",
    "\n",
    "    t1 = PythonOperator(\n",
    "        task_id=\"task1\",\n",
    "        python_callable=run_task,\n",
    "        op_args=[\"task1\"],\n",
    "    )\n",
    "\n",
    "    t2 = PythonOperator(\n",
    "        task_id=\"task2\",\n",
    "        python_callable=run_task,\n",
    "        op_args=[\"task2\"],\n",
    "    )\n",
    "# test 1\n",
    "# t2 runs after t1\n",
    "    t1 >> t2\n",
    "```"
   ],
   "id": "b56765be42183773"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2da561e0bdedc9a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "efc3d10a93c37cf6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
